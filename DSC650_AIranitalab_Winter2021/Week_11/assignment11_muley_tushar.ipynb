{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Tushar Muley\n",
    "\n",
    "Assignment: Assignment 11\n",
    "\n",
    "Date: February 13, 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import keras\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/nietzsche.txt\n",
      "606208/600901 [==============================] - 0s 1us/step\n",
      "Corpus length: 600893\n"
     ]
    }
   ],
   "source": [
    "path = keras.utils.get_file(\n",
    "'nietzsche.txt',\n",
    "origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "text = open(path).read().lower()\n",
    "print('Corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequences: 200278\n",
      "Unique characters: 57\n",
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    " # extract sequences of 60 characters\n",
    "maxlen = 60\n",
    "\n",
    "# sample a new sequence every three characters\n",
    "step = 3\n",
    "\n",
    "# hold the extracted sequences\n",
    "sentences = []\n",
    "\n",
    "# holds the targets (the follow-up characters)\n",
    "next_chars = []\n",
    "\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "\n",
    "print('Sequences:', len(sentences))\n",
    "\n",
    "# list of characters in eron data\n",
    "chars = sorted(list(set(text)))\n",
    "print('Unique characters:', len(chars))\n",
    "\n",
    "# maps characters to their index\n",
    "char_indices = dict((char, chars.index(char)) for char in chars)\n",
    "\n",
    "print('Vectorization...')\n",
    "\n",
    "\n",
    "# one-hot encode the characters into binary arrays\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single-layer LSTM model for next-chracter prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single-layer LSTM\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(layers.LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(layers.Dense(len(chars), activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model compilation configuration\n",
    "\n",
    "optimizer = keras.optimizers.RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to sample the next character\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "1565/1565 [==============================] - 199s 127ms/step - loss: 1.9554\n",
      "--- Generating with seed: \"sight of it would necessarily seduce and constrain to sympat\"\n",
      "------ temperature: 0.2\n",
      "sight of it would necessarily seduce and constrain to sympath------ temperature: 0.5\n",
      "ight of it would necessarily seduce and constrain to sympathy------ temperature: 1.0\n",
      "ght of it would necessarily seduce and constrain to sympathy,------ temperature: 1.2\n",
      "ht of it would necessarily seduce and constrain to sympathy, \n",
      "epoch 2\n",
      "1565/1565 [==============================] - 198s 126ms/step - loss: 1.6127\n",
      "--- Generating with seed: \"y and dangerous isolation, as a saint: for it is just\n",
      "holine\"\n",
      "------ temperature: 0.2\n",
      "y and dangerous isolation, as a saint: for it is just\n",
      "holines------ temperature: 0.5\n",
      " and dangerous isolation, as a saint: for it is just\n",
      "holines,------ temperature: 1.0\n",
      "and dangerous isolation, as a saint: for it is just\n",
      "holines, ------ temperature: 1.2\n",
      "nd dangerous isolation, as a saint: for it is just\n",
      "holines, t\n",
      "epoch 3\n",
      "1565/1565 [==============================] - 198s 126ms/step - loss: 1.5264\n",
      "--- Generating with seed: \"o\n",
      "dangerous voyages of discovery, to spiritualized north pol\"\n",
      "------ temperature: 0.2\n",
      "o\n",
      "dangerous voyages of discovery, to spiritualized north poli------ temperature: 0.5\n",
      "\n",
      "dangerous voyages of discovery, to spiritualized north polit------ temperature: 1.0\n",
      "dangerous voyages of discovery, to spiritualized north politi------ temperature: 1.2\n",
      "angerous voyages of discovery, to spiritualized north politio\n",
      "epoch 4\n",
      "1565/1565 [==============================] - 198s 126ms/step - loss: 1.4804\n",
      "--- Generating with seed: \"erhaps, gives his approval\n",
      "to that which has heretofore been\"\n",
      "------ temperature: 0.2\n",
      "erhaps, gives his approval\n",
      "to that which has heretofore been ------ temperature: 0.5\n",
      "rhaps, gives his approval\n",
      "to that which has heretofore been h------ temperature: 1.0\n",
      "haps, gives his approval\n",
      "to that which has heretofore been ho------ temperature: 1.2\n",
      "aps, gives his approval\n",
      "to that which has heretofore been how\n",
      "epoch 5\n",
      "1565/1565 [==============================] - 198s 126ms/step - loss: 1.4496\n",
      "--- Generating with seed: \"ght and color? it posits as the inducing causes of such\n",
      "ligh\"\n",
      "------ temperature: 0.2\n",
      "ght and color? it posits as the inducing causes of such\n",
      "light------ temperature: 0.5\n",
      "ht and color? it posits as the inducing causes of such\n",
      "light ------ temperature: 1.0\n",
      "t and color? it posits as the inducing causes of such\n",
      "light a------ temperature: 1.2\n",
      " and color? it posits as the inducing causes of such\n",
      "light an\n",
      "epoch 6\n",
      "1565/1565 [==============================] - 197s 126ms/step - loss: 1.4305\n",
      "--- Generating with seed: \"reduced to\n",
      "imperfect men, to slaves and instruments. its fun\"\n",
      "------ temperature: 0.2\n",
      "reduced to\n",
      "imperfect men, to slaves and instruments. its fund------ temperature: 0.5\n",
      "educed to\n",
      "imperfect men, to slaves and instruments. its funda------ temperature: 1.0\n",
      "duced to\n",
      "imperfect men, to slaves and instruments. its fundam------ temperature: 1.2\n",
      "uced to\n",
      "imperfect men, to slaves and instruments. its fundame\n",
      "epoch 7\n",
      "1565/1565 [==============================] - 198s 126ms/step - loss: 1.4116\n",
      "--- Generating with seed: \"s, as has\n",
      "been taught by hafis and goethe, the bold letting-\"\n",
      "------ temperature: 0.2\n",
      "s, as has\n",
      "been taught by hafis and goethe, the bold letting-------- temperature: 0.5\n",
      ", as has\n",
      "been taught by hafis and goethe, the bold letting--t------ temperature: 1.0\n",
      " as has\n",
      "been taught by hafis and goethe, the bold letting--th------ temperature: 1.2\n",
      "as has\n",
      "been taught by hafis and goethe, the bold letting--the\n",
      "epoch 8\n",
      "1565/1565 [==============================] - 198s 126ms/step - loss: 1.3964\n",
      "--- Generating with seed: \"obtrusive touches and\n",
      "incivilities: something that goes its \"\n",
      "------ temperature: 0.2\n",
      "obtrusive touches and\n",
      "incivilities: something that goes its w------ temperature: 0.5\n",
      "btrusive touches and\n",
      "incivilities: something that goes its wo------ temperature: 1.0\n",
      "trusive touches and\n",
      "incivilities: something that goes its wor------ temperature: 1.2\n",
      "rusive touches and\n",
      "incivilities: something that goes its worl\n",
      "epoch 9\n",
      "1565/1565 [==============================] - 198s 127ms/step - loss: 1.3865\n",
      "--- Generating with seed: \"erman depth is often only a difficult, hesitating\n",
      "\"digestion\"\n",
      "------ temperature: 0.2\n",
      "erman depth is often only a difficult, hesitating\n",
      "\"digestion ------ temperature: 0.5\n",
      "rman depth is often only a difficult, hesitating\n",
      "\"digestion o------ temperature: 1.0\n",
      "man depth is often only a difficult, hesitating\n",
      "\"digestion of------ temperature: 1.2\n",
      "an depth is often only a difficult, hesitating\n",
      "\"digestion of \n",
      "epoch 10\n",
      "1565/1565 [==============================] - 197s 126ms/step - loss: 1.3753\n",
      "--- Generating with seed: \"elf abnegation and not in revenge the element\n",
      "of greatness c\"\n",
      "------ temperature: 0.2\n",
      "elf abnegation and not in revenge the element\n",
      "of greatness ca------ temperature: 0.5\n",
      "lf abnegation and not in revenge the element\n",
      "of greatness can------ temperature: 1.0\n",
      "f abnegation and not in revenge the element\n",
      "of greatness can ------ temperature: 1.2\n",
      " abnegation and not in revenge the element\n",
      "of greatness can b\n",
      "epoch 11\n",
      "1565/1565 [==============================] - 198s 126ms/step - loss: 1.3681\n",
      "--- Generating with seed: \" leads man to war\n",
      "upon himself and makes him uncertain, dist\"\n",
      "------ temperature: 0.2\n",
      " leads man to war\n",
      "upon himself and makes him uncertain, disti------ temperature: 0.5\n",
      "leads man to war\n",
      "upon himself and makes him uncertain, distin------ temperature: 1.0\n",
      "eads man to war\n",
      "upon himself and makes him uncertain, disting------ temperature: 1.2\n",
      "ads man to war\n",
      "upon himself and makes him uncertain, distingu\n",
      "epoch 12\n",
      "1565/1565 [==============================] - 198s 126ms/step - loss: 1.3597\n",
      "--- Generating with seed: \"--but who can doubt that it will be over still sooner with\n",
      "t\"\n",
      "------ temperature: 0.2\n",
      "--but who can doubt that it will be over still sooner with\n",
      "th------ temperature: 0.5\n",
      "-but who can doubt that it will be over still sooner with\n",
      "the------ temperature: 1.0\n",
      "but who can doubt that it will be over still sooner with\n",
      "the\n",
      "------ temperature: 1.2\n",
      "ut who can doubt that it will be over still sooner with\n",
      "the\n",
      "f\n",
      "epoch 13\n",
      "1565/1565 [==============================] - 198s 126ms/step - loss: 1.3523\n",
      "--- Generating with seed: \"er, further, more extended, more\n",
      "comprehensive states, in sh\"\n",
      "------ temperature: 0.2\n",
      "er, further, more extended, more\n",
      "comprehensive states, in sho------ temperature: 0.5\n",
      "r, further, more extended, more\n",
      "comprehensive states, in shor------ temperature: 1.0\n",
      ", further, more extended, more\n",
      "comprehensive states, in short------ temperature: 1.2\n",
      " further, more extended, more\n",
      "comprehensive states, in short,\n",
      "epoch 14\n",
      "1565/1565 [==============================] - 197s 126ms/step - loss: 1.3469\n",
      "--- Generating with seed: \"vantage: the crude, undeveloped, rough individualities will \"\n",
      "------ temperature: 0.2\n",
      "vantage: the crude, undeveloped, rough individualities will b------ temperature: 0.5\n",
      "antage: the crude, undeveloped, rough individualities will be------ temperature: 1.0\n",
      "ntage: the crude, undeveloped, rough individualities will be ------ temperature: 1.2\n",
      "tage: the crude, undeveloped, rough individualities will be n\n",
      "epoch 15\n",
      "1565/1565 [==============================] - 198s 126ms/step - loss: 1.3412\n",
      "--- Generating with seed: \"bible. the distorted and diseased\n",
      "in his own nature with its\"\n",
      "------ temperature: 0.2\n",
      "bible. the distorted and diseased\n",
      "in his own nature with its ------ temperature: 0.5\n",
      "ible. the distorted and diseased\n",
      "in his own nature with its w------ temperature: 1.0\n",
      "ble. the distorted and diseased\n",
      "in his own nature with its wh------ temperature: 1.2\n",
      "le. the distorted and diseased\n",
      "in his own nature with its who\n",
      "epoch 16\n",
      "1565/1565 [==============================] - 198s 127ms/step - loss: 1.3360\n",
      "--- Generating with seed: \"volve\n",
      "once more in the same orbit, however independent of ea\"\n",
      "------ temperature: 0.2\n",
      "volve\n",
      "once more in the same orbit, however independent of ear------ temperature: 0.5\n",
      "olve\n",
      "once more in the same orbit, however independent of eart------ temperature: 1.0\n",
      "lve\n",
      "once more in the same orbit, however independent of earth------ temperature: 1.2\n",
      "ve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "once more in the same orbit, however independent of earth-\n",
      "epoch 17\n",
      "1565/1565 [==============================] - 197s 126ms/step - loss: 1.3305\n",
      "--- Generating with seed: \"hicle for\n",
      "your inclinations,--ye, too, really find the noise\"\n",
      "------ temperature: 0.2\n",
      "hicle for\n",
      "your inclinations,--ye, too, really find the noise ------ temperature: 0.5\n",
      "icle for\n",
      "your inclinations,--ye, too, really find the noise i------ temperature: 1.0\n",
      "cle for\n",
      "your inclinations,--ye, too, really find the noise it------ temperature: 1.2\n",
      "le for\n",
      "your inclinations,--ye, too, really find the noise its\n",
      "epoch 18\n",
      "1565/1565 [==============================] - 197s 126ms/step - loss: 1.3265\n",
      "--- Generating with seed: \"nifests is a consolation to the weak and suffering only in a\"\n",
      "------ temperature: 0.2\n",
      "nifests is a consolation to the weak and suffering only in a ------ temperature: 0.5\n",
      "ifests is a consolation to the weak and suffering only in a c------ temperature: 1.0\n",
      "fests is a consolation to the weak and suffering only in a cl------ temperature: 1.2\n",
      "ests is a consolation to the weak and suffering only in a cla\n",
      "epoch 19\n",
      "1565/1565 [==============================] - 197s 126ms/step - loss: 1.3211\n",
      "--- Generating with seed: \"erceived that in the most personal\n",
      "considerations the most g\"\n",
      "------ temperature: 0.2\n",
      "erceived that in the most personal\n",
      "considerations the most gr------ temperature: 0.5\n",
      "rceived that in the most personal\n",
      "considerations the most gre------ temperature: 1.0\n",
      "ceived that in the most personal\n",
      "considerations the most grea------ temperature: 1.2\n",
      "eived that in the most personal\n",
      "considerations the most great\n"
     ]
    }
   ],
   "source": [
    "# train the model for 20 examples\n",
    "\n",
    "for epoch in range(1, 20):\n",
    "    print('epoch', epoch)\n",
    "\n",
    "# fit the model for one iteration on the data\n",
    "    model.fit(x, y, batch_size=128, epochs=1)\n",
    "\n",
    "    # select a text seed at random\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    generated_text = text[start_index: start_index + maxlen]\n",
    "    print('--- Generating with seed: \"' + generated_text + '\"')\n",
    "\n",
    "    # different sampling temperatures\n",
    "\n",
    "    for temperature in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('------ temperature:', temperature)\n",
    "        sys.stdout.write(generated_text)\n",
    "\n",
    "        # generates 400 characters, from seed text\n",
    "        for i in range(400):\n",
    "\n",
    "            # one-hot encodes the characters genrated so far\n",
    "            sampled = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(generated_text):\n",
    "                sampled[0, t, char_indices[char]] = 1.\n",
    "\n",
    "        # samples the next character\n",
    "        preds = model.predict(sampled, verbose=0)[0]\n",
    "        next_index = sample(preds, temperature)\n",
    "        next_char = chars[next_index]\n",
    "        \n",
    "        generated_text += next_char\n",
    "        generated_text = generated_text[1:]\n",
    "        \n",
    "        sys.stdout.write(next_char)\n",
    "        sys.stdout.flush()\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
