{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Muley, Tushar\n",
    "\n",
    "Title: Exercise_9-3_Week_9\n",
    "\n",
    "Date: May 23, 2021\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Neural Network Classifier with Scikit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the multi-label classifier dataset from earlier exercises (categorized-comments.jsonl in the reddit folder), fit a neural network classifier using scikit-learn. Use the code found in chapter 12 of the Applied Text Analysis with Python book as a guideline. Report the accuracy, precision, recall, F1-score, and confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import numpy as np # For numerical fast numerical calculations\n",
    "import matplotlib.pyplot as plt # For making plots\n",
    "import pandas as pd # Deals with data\n",
    "import seaborn as sns # Makes beautiful plots\n",
    "from sklearn.preprocessing import StandardScaler # Testing sklearn\n",
    "import tensorflow # Imports tensorflow\n",
    "import keras # Imports keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sports</td>\n",
       "      <td>Barely better than Gabbert? He was significant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sports</td>\n",
       "      <td>Fuck the ducks and the Angels! But welcome to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sports</td>\n",
       "      <td>Should have drafted more WRs.\\n\\n- Matt Millen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sports</td>\n",
       "      <td>[Done](https://i.imgur.com/2YZ90pm.jpg)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sports</td>\n",
       "      <td>No!! NOO!!!!!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cat                                                txt\n",
       "0  sports  Barely better than Gabbert? He was significant...\n",
       "1  sports  Fuck the ducks and the Angels! But welcome to ...\n",
       "2  sports  Should have drafted more WRs.\\n\\n- Matt Millen...\n",
       "3  sports            [Done](https://i.imgur.com/2YZ90pm.jpg)\n",
       "4  sports                                      No!! NOO!!!!!"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read the file\n",
    "jfile = \"categorized-comments.jsonl\" #File location\n",
    "file = pd.read_json(jfile,lines=True) #Read command\n",
    "file.head() #Check the datarame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the multi-label classifier dataset from earlier exercises (categorized-comments.jsonl in the reddit folder),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(606476, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Size of the dataframe\n",
    "file.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sports</td>\n",
       "      <td>barely better than gabbert he was significantl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sports</td>\n",
       "      <td>fuck the ducks and the angels but welcome to a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sports</td>\n",
       "      <td>should have drafted more wrs\\n\\n matt millen p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sports</td>\n",
       "      <td>donehttpsiimgurcom2yz90pmjpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sports</td>\n",
       "      <td>no noo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cat                                                txt\n",
       "0  sports  barely better than gabbert he was significantl...\n",
       "1  sports  fuck the ducks and the angels but welcome to a...\n",
       "2  sports  should have drafted more wrs\\n\\n matt millen p...\n",
       "3  sports                       donehttpsiimgurcom2yz90pmjpg\n",
       "4  sports                                             no noo"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lowercase the data\n",
    "file[\"txt\"] = file[\"txt\"].str.lower()\n",
    "#View the top 5 rows\n",
    "\n",
    "#Remove punctuation\n",
    "file[\"txt\"] = file[\"txt\"].str.replace(\"[^\\w\\s]\", \"\")\n",
    "#View the top 5 rows\n",
    "file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Tushar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Tushar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Download stopwords and punkt\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import NLKT, stopwords and tokenize\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "#Set the stop_words\n",
    "stop_words = stopwords.words(\"english\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>txt</th>\n",
       "      <th>tokenized_sents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sports</td>\n",
       "      <td>barely better than gabbert he was significantl...</td>\n",
       "      <td>[barely, better, than, gabbert, he, was, signi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sports</td>\n",
       "      <td>fuck the ducks and the angels but welcome to a...</td>\n",
       "      <td>[fuck, the, ducks, and, the, angels, but, welc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sports</td>\n",
       "      <td>should have drafted more wrs\\n\\n matt millen p...</td>\n",
       "      <td>[should, have, drafted, more, wrs, matt, mille...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sports</td>\n",
       "      <td>donehttpsiimgurcom2yz90pmjpg</td>\n",
       "      <td>[donehttpsiimgurcom2yz90pmjpg]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sports</td>\n",
       "      <td>no noo</td>\n",
       "      <td>[no, noo]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cat                                                txt  \\\n",
       "0  sports  barely better than gabbert he was significantl...   \n",
       "1  sports  fuck the ducks and the angels but welcome to a...   \n",
       "2  sports  should have drafted more wrs\\n\\n matt millen p...   \n",
       "3  sports                       donehttpsiimgurcom2yz90pmjpg   \n",
       "4  sports                                             no noo   \n",
       "\n",
       "                                     tokenized_sents  \n",
       "0  [barely, better, than, gabbert, he, was, signi...  \n",
       "1  [fuck, the, ducks, and, the, angels, but, welc...  \n",
       "2  [should, have, drafted, more, wrs, matt, mille...  \n",
       "3                     [donehttpsiimgurcom2yz90pmjpg]  \n",
       "4                                          [no, noo]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tokenize the text\n",
    "file[\"tokenized_sents\"] = file.apply(lambda row: word_tokenize(row[\"txt\"]), axis=1)\n",
    "\n",
    "#Preview the file\n",
    "file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>txt</th>\n",
       "      <th>tokenized_sents</th>\n",
       "      <th>removed_stop_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sports</td>\n",
       "      <td>barely better than gabbert he was significantl...</td>\n",
       "      <td>[barely, better, than, gabbert, he, was, signi...</td>\n",
       "      <td>[barely, better, than, gabbert, he, was, signi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sports</td>\n",
       "      <td>fuck the ducks and the angels but welcome to a...</td>\n",
       "      <td>[fuck, the, ducks, and, the, angels, but, welc...</td>\n",
       "      <td>[fuck, the, ducks, and, the, angels, but, welc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sports</td>\n",
       "      <td>should have drafted more wrs\\n\\n matt millen p...</td>\n",
       "      <td>[should, have, drafted, more, wrs, matt, mille...</td>\n",
       "      <td>[should, have, drafted, more, wrs, matt, mille...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sports</td>\n",
       "      <td>donehttpsiimgurcom2yz90pmjpg</td>\n",
       "      <td>[donehttpsiimgurcom2yz90pmjpg]</td>\n",
       "      <td>[donehttpsiimgurcom2yz90pmjpg]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sports</td>\n",
       "      <td>no noo</td>\n",
       "      <td>[no, noo]</td>\n",
       "      <td>[no, noo]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cat                                                txt  \\\n",
       "0  sports  barely better than gabbert he was significantl...   \n",
       "1  sports  fuck the ducks and the angels but welcome to a...   \n",
       "2  sports  should have drafted more wrs\\n\\n matt millen p...   \n",
       "3  sports                       donehttpsiimgurcom2yz90pmjpg   \n",
       "4  sports                                             no noo   \n",
       "\n",
       "                                     tokenized_sents  \\\n",
       "0  [barely, better, than, gabbert, he, was, signi...   \n",
       "1  [fuck, the, ducks, and, the, angels, but, welc...   \n",
       "2  [should, have, drafted, more, wrs, matt, mille...   \n",
       "3                     [donehttpsiimgurcom2yz90pmjpg]   \n",
       "4                                          [no, noo]   \n",
       "\n",
       "                                  removed_stop_words  \n",
       "0  [barely, better, than, gabbert, he, was, signi...  \n",
       "1  [fuck, the, ducks, and, the, angels, but, welc...  \n",
       "2  [should, have, drafted, more, wrs, matt, mille...  \n",
       "3                     [donehttpsiimgurcom2yz90pmjpg]  \n",
       "4                                          [no, noo]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove stop words\n",
    "file[\"removed_stop_words\"]=[word for word in file[\"tokenized_sents\"] if word not in stop_words]\n",
    "\n",
    "#Preview words\n",
    "file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import PorterStemmer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "#Create stemmer\n",
    "porter = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>txt</th>\n",
       "      <th>tokenized_sents</th>\n",
       "      <th>removed_stop_words</th>\n",
       "      <th>stemmer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sports</td>\n",
       "      <td>barely better than gabbert he was significantl...</td>\n",
       "      <td>[barely, better, than, gabbert, he, was, signi...</td>\n",
       "      <td>[barely, better, than, gabbert, he, was, signi...</td>\n",
       "      <td>[bare, better, than, gabbert, he, wa, signific...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sports</td>\n",
       "      <td>fuck the ducks and the angels but welcome to a...</td>\n",
       "      <td>[fuck, the, ducks, and, the, angels, but, welc...</td>\n",
       "      <td>[fuck, the, ducks, and, the, angels, but, welc...</td>\n",
       "      <td>[fuck, the, duck, and, the, angel, but, welcom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sports</td>\n",
       "      <td>should have drafted more wrs\\n\\n matt millen p...</td>\n",
       "      <td>[should, have, drafted, more, wrs, matt, mille...</td>\n",
       "      <td>[should, have, drafted, more, wrs, matt, mille...</td>\n",
       "      <td>[should, have, draft, more, wr, matt, millen, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sports</td>\n",
       "      <td>donehttpsiimgurcom2yz90pmjpg</td>\n",
       "      <td>[donehttpsiimgurcom2yz90pmjpg]</td>\n",
       "      <td>[donehttpsiimgurcom2yz90pmjpg]</td>\n",
       "      <td>[donehttpsiimgurcom2yz90pmjpg]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sports</td>\n",
       "      <td>no noo</td>\n",
       "      <td>[no, noo]</td>\n",
       "      <td>[no, noo]</td>\n",
       "      <td>[no, noo]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cat                                                txt  \\\n",
       "0  sports  barely better than gabbert he was significantl...   \n",
       "1  sports  fuck the ducks and the angels but welcome to a...   \n",
       "2  sports  should have drafted more wrs\\n\\n matt millen p...   \n",
       "3  sports                       donehttpsiimgurcom2yz90pmjpg   \n",
       "4  sports                                             no noo   \n",
       "\n",
       "                                     tokenized_sents  \\\n",
       "0  [barely, better, than, gabbert, he, was, signi...   \n",
       "1  [fuck, the, ducks, and, the, angels, but, welc...   \n",
       "2  [should, have, drafted, more, wrs, matt, mille...   \n",
       "3                     [donehttpsiimgurcom2yz90pmjpg]   \n",
       "4                                          [no, noo]   \n",
       "\n",
       "                                  removed_stop_words  \\\n",
       "0  [barely, better, than, gabbert, he, was, signi...   \n",
       "1  [fuck, the, ducks, and, the, angels, but, welc...   \n",
       "2  [should, have, drafted, more, wrs, matt, mille...   \n",
       "3                     [donehttpsiimgurcom2yz90pmjpg]   \n",
       "4                                          [no, noo]   \n",
       "\n",
       "                                             stemmer  \n",
       "0  [bare, better, than, gabbert, he, wa, signific...  \n",
       "1  [fuck, the, duck, and, the, angel, but, welcom...  \n",
       "2  [should, have, draft, more, wr, matt, millen, ...  \n",
       "3                     [donehttpsiimgurcom2yz90pmjpg]  \n",
       "4                                          [no, noo]  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run stemmer\n",
    "file[\"stemmer\"]= file[\"removed_stop_words\"].apply(lambda x: [porter.stem(word) for word in x])\n",
    "#View the file\n",
    "file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(606476, 5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the size of the data\n",
    "file.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>txt</th>\n",
       "      <th>tokenized_sents</th>\n",
       "      <th>removed_stop_words</th>\n",
       "      <th>stemmer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sports</td>\n",
       "      <td>barely better than gabbert he was significantl...</td>\n",
       "      <td>[barely, better, than, gabbert, he, was, signi...</td>\n",
       "      <td>[barely, better, than, gabbert, he, was, signi...</td>\n",
       "      <td>[bare, better, than, gabbert, he, wa, signific...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sports</td>\n",
       "      <td>fuck the ducks and the angels but welcome to a...</td>\n",
       "      <td>[fuck, the, ducks, and, the, angels, but, welc...</td>\n",
       "      <td>[fuck, the, ducks, and, the, angels, but, welc...</td>\n",
       "      <td>[fuck, the, duck, and, the, angel, but, welcom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sports</td>\n",
       "      <td>should have drafted more wrs\\n\\n matt millen p...</td>\n",
       "      <td>[should, have, drafted, more, wrs, matt, mille...</td>\n",
       "      <td>[should, have, drafted, more, wrs, matt, mille...</td>\n",
       "      <td>[should, have, draft, more, wr, matt, millen, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sports</td>\n",
       "      <td>donehttpsiimgurcom2yz90pmjpg</td>\n",
       "      <td>[donehttpsiimgurcom2yz90pmjpg]</td>\n",
       "      <td>[donehttpsiimgurcom2yz90pmjpg]</td>\n",
       "      <td>[donehttpsiimgurcom2yz90pmjpg]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sports</td>\n",
       "      <td>no noo</td>\n",
       "      <td>[no, noo]</td>\n",
       "      <td>[no, noo]</td>\n",
       "      <td>[no, noo]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cat                                                txt  \\\n",
       "0  sports  barely better than gabbert he was significantl...   \n",
       "1  sports  fuck the ducks and the angels but welcome to a...   \n",
       "2  sports  should have drafted more wrs\\n\\n matt millen p...   \n",
       "3  sports                       donehttpsiimgurcom2yz90pmjpg   \n",
       "4  sports                                             no noo   \n",
       "\n",
       "                                     tokenized_sents  \\\n",
       "0  [barely, better, than, gabbert, he, was, signi...   \n",
       "1  [fuck, the, ducks, and, the, angels, but, welc...   \n",
       "2  [should, have, drafted, more, wrs, matt, mille...   \n",
       "3                     [donehttpsiimgurcom2yz90pmjpg]   \n",
       "4                                          [no, noo]   \n",
       "\n",
       "                                  removed_stop_words  \\\n",
       "0  [barely, better, than, gabbert, he, was, signi...   \n",
       "1  [fuck, the, ducks, and, the, angels, but, welc...   \n",
       "2  [should, have, drafted, more, wrs, matt, mille...   \n",
       "3                     [donehttpsiimgurcom2yz90pmjpg]   \n",
       "4                                          [no, noo]   \n",
       "\n",
       "                                             stemmer  \n",
       "0  [bare, better, than, gabbert, he, wa, signific...  \n",
       "1  [fuck, the, duck, and, the, angel, but, welcom...  \n",
       "2  [should, have, draft, more, wr, matt, millen, ...  \n",
       "3                     [donehttpsiimgurcom2yz90pmjpg]  \n",
       "4                                          [no, noo]  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Copy of file check point\n",
    "df_file_copy = file.copy(deep=True)\n",
    "\n",
    "#Only use if needed to get orignal copy\n",
    "#file = df_file_copy.copy(deep=True)\n",
    "\n",
    "#Preview\n",
    "file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>txt</th>\n",
       "      <th>tokenized_sents</th>\n",
       "      <th>removed_stop_words</th>\n",
       "      <th>stemmer</th>\n",
       "      <th>txt_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sports</td>\n",
       "      <td>barely better than gabbert he was significantl...</td>\n",
       "      <td>[barely, better, than, gabbert, he, was, signi...</td>\n",
       "      <td>[barely, better, than, gabbert, he, was, signi...</td>\n",
       "      <td>[bare, better, than, gabbert, he, wa, signific...</td>\n",
       "      <td>bare better than gabbert he wa significantli b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sports</td>\n",
       "      <td>fuck the ducks and the angels but welcome to a...</td>\n",
       "      <td>[fuck, the, ducks, and, the, angels, but, welc...</td>\n",
       "      <td>[fuck, the, ducks, and, the, angels, but, welc...</td>\n",
       "      <td>[fuck, the, duck, and, the, angel, but, welcom...</td>\n",
       "      <td>fuck the duck and the angel but welcom to all ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sports</td>\n",
       "      <td>should have drafted more wrs\\n\\n matt millen p...</td>\n",
       "      <td>[should, have, drafted, more, wrs, matt, mille...</td>\n",
       "      <td>[should, have, drafted, more, wrs, matt, mille...</td>\n",
       "      <td>[should, have, draft, more, wr, matt, millen, ...</td>\n",
       "      <td>should have draft more wr matt millen probabl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sports</td>\n",
       "      <td>donehttpsiimgurcom2yz90pmjpg</td>\n",
       "      <td>[donehttpsiimgurcom2yz90pmjpg]</td>\n",
       "      <td>[donehttpsiimgurcom2yz90pmjpg]</td>\n",
       "      <td>[donehttpsiimgurcom2yz90pmjpg]</td>\n",
       "      <td>donehttpsiimgurcom2yz90pmjpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sports</td>\n",
       "      <td>no noo</td>\n",
       "      <td>[no, noo]</td>\n",
       "      <td>[no, noo]</td>\n",
       "      <td>[no, noo]</td>\n",
       "      <td>no noo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cat                                                txt  \\\n",
       "0  sports  barely better than gabbert he was significantl...   \n",
       "1  sports  fuck the ducks and the angels but welcome to a...   \n",
       "2  sports  should have drafted more wrs\\n\\n matt millen p...   \n",
       "3  sports                       donehttpsiimgurcom2yz90pmjpg   \n",
       "4  sports                                             no noo   \n",
       "\n",
       "                                     tokenized_sents  \\\n",
       "0  [barely, better, than, gabbert, he, was, signi...   \n",
       "1  [fuck, the, ducks, and, the, angels, but, welc...   \n",
       "2  [should, have, drafted, more, wrs, matt, mille...   \n",
       "3                     [donehttpsiimgurcom2yz90pmjpg]   \n",
       "4                                          [no, noo]   \n",
       "\n",
       "                                  removed_stop_words  \\\n",
       "0  [barely, better, than, gabbert, he, was, signi...   \n",
       "1  [fuck, the, ducks, and, the, angels, but, welc...   \n",
       "2  [should, have, drafted, more, wrs, matt, mille...   \n",
       "3                     [donehttpsiimgurcom2yz90pmjpg]   \n",
       "4                                          [no, noo]   \n",
       "\n",
       "                                             stemmer  \\\n",
       "0  [bare, better, than, gabbert, he, wa, signific...   \n",
       "1  [fuck, the, duck, and, the, angel, but, welcom...   \n",
       "2  [should, have, draft, more, wr, matt, millen, ...   \n",
       "3                     [donehttpsiimgurcom2yz90pmjpg]   \n",
       "4                                          [no, noo]   \n",
       "\n",
       "                                           txt_final  \n",
       "0  bare better than gabbert he wa significantli b...  \n",
       "1  fuck the duck and the angel but welcom to all ...  \n",
       "2      should have draft more wr matt millen probabl  \n",
       "3                       donehttpsiimgurcom2yz90pmjpg  \n",
       "4                                             no noo  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#put the text back together string it\n",
    "file[\"txt_final\"]= file[\"stemmer\"].apply(lambda text:' '.join(text))\n",
    "#view the pre-processed text\n",
    "file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copy data check point\n",
    "df_file_copy2 = file.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>txt_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sports</td>\n",
       "      <td>bare better than gabbert he wa significantli b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sports</td>\n",
       "      <td>fuck the duck and the angel but welcom to all ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sports</td>\n",
       "      <td>should have draft more wr matt millen probabl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sports</td>\n",
       "      <td>donehttpsiimgurcom2yz90pmjpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sports</td>\n",
       "      <td>no noo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cat                                          txt_final\n",
       "0  sports  bare better than gabbert he wa significantli b...\n",
       "1  sports  fuck the duck and the angel but welcom to all ...\n",
       "2  sports      should have draft more wr matt millen probabl\n",
       "3  sports                       donehttpsiimgurcom2yz90pmjpg\n",
       "4  sports                                             no noo"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Drop un-need columns\n",
    "\n",
    "file=file.drop([\"txt\", \"tokenized_sents\", \"removed_stop_words\", \"stemmer\"], axis=1)\n",
    "file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(606476, 2)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check size of file\n",
    "file.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample to redue the size of the data set\n",
    "file_small=file.sample(n = 60000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 2)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check size\n",
    "file_small.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>txt_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>408464</th>\n",
       "      <td>video_games</td>\n",
       "      <td>ha it been announc if sonic mania is get physi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545789</th>\n",
       "      <td>video_games</td>\n",
       "      <td>that half true but pro team with max money on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157080</th>\n",
       "      <td>video_games</td>\n",
       "      <td>whatev float your boat mate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138498</th>\n",
       "      <td>video_games</td>\n",
       "      <td>cheeki light up the backsid at the end there</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590515</th>\n",
       "      <td>video_games</td>\n",
       "      <td>httpplaystvvideo585e42248d71bde305360fromus same</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                cat                                          txt_final\n",
       "408464  video_games  ha it been announc if sonic mania is get physi...\n",
       "545789  video_games  that half true but pro team with max money on ...\n",
       "157080  video_games                        whatev float your boat mate\n",
       "138498  video_games       cheeki light up the backsid at the end there\n",
       "590515  video_games   httpplaystvvideo585e42248d71bde305360fromus same"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Preview the data set\n",
    "file_small.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bring in CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 39535)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create the bag of words features Features = X\n",
    "count=CountVectorizer()\n",
    "X=count.fit_transform(file_small[\"txt_final\"])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<60000x39535 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1221428 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#All my targets Target = y\n",
    "y=file_small[\"cat\"]\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "408464               video_games\n",
       "545789               video_games\n",
       "157080               video_games\n",
       "138498               video_games\n",
       "590515               video_games\n",
       "                   ...          \n",
       "437435               video_games\n",
       "22592     science_and_technology\n",
       "526688               video_games\n",
       "589654               video_games\n",
       "406959               video_games\n",
       "Name: cat, Length: 60000, dtype: object"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Split the data into train and text dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size = 0.20, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Training set: (48000, 39535)\n",
      "Y Training set: (48000,)\n",
      "X Test: (12000, 39535)\n",
      "Y Test: (12000,)\n"
     ]
    }
   ],
   "source": [
    "#Preview the train test dataset\n",
    "print('X Training set:',X_train.shape)\n",
    "\n",
    "print ('Y Training set:',y_train.shape)\n",
    "\n",
    "print ('X Test:',X_test.shape)\n",
    "\n",
    "print ('Y Test:',y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(with_mean=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import standard Scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "\n",
    "#Fit only the training data\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply the transformations to data:\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import classeifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tushar\\anaconda3\\envs\\PythonCPU\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:587: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(5, 2))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Instance of the model.\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(5,2))\n",
    "#Fit the training data to our model\n",
    "mlp.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model is trained now test the model.\n",
    "predictions = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  3455    129   2734]\n",
      " [   130  23473  12899]\n",
      " [  1084   5158 102557]]\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "science_and_technology       0.74      0.55      0.63      6318\n",
      "                sports       0.82      0.64      0.72     36502\n",
      "           video_games       0.87      0.94      0.90    108799\n",
      "\n",
      "              accuracy                           0.85    151619\n",
      "             macro avg       0.81      0.71      0.75    151619\n",
      "          weighted avg       0.85      0.85      0.85    151619\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Import classification and confusion matrix\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test,predictions))\n",
    " \n",
    "print(classification_report(y_test,predictions))\n",
    "\n",
    "#print(accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(30, 30, 30))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Instance of the model.\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(30,30,30),verbose=False)\n",
    "#Fit the training data to our model\n",
    "mlp.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model is trained now test the model.\n",
    "predictions = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 223   42  239]\n",
      " [  43 1781 1078]\n",
      " [ 142  873 7579]]\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "science_and_technology       0.55      0.44      0.49       504\n",
      "                sports       0.66      0.61      0.64      2902\n",
      "           video_games       0.85      0.88      0.87      8594\n",
      "\n",
      "              accuracy                           0.80     12000\n",
      "             macro avg       0.69      0.65      0.66     12000\n",
      "          weighted avg       0.79      0.80      0.80     12000\n",
      "\n",
      "0.7985833333333333\n"
     ]
    }
   ],
   "source": [
    "#Import classification and confusion matrix\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_test,predictions))\n",
    " \n",
    "print(classification_report(y_test,predictions))\n",
    " \n",
    "print(accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data  0.7985833333333333\n",
      "Accuracy on train data  0.9783958333333334\n"
     ]
    }
   ],
   "source": [
    "#Accuracy of test and train\n",
    "print('Accuracy on test data ', mlp.score(X_test,y_test))\n",
    "print('Accuracy on train data ', mlp.score(X_train,y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report the accuracy, \n",
    "precision, \n",
    "recall, \n",
    "F1-score, \n",
    "confusion matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy\n",
    "\n",
    "Accuracy on test data  0.7985833333333333\n",
    "Accuracy on train data  0.9783958333333334\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precision \n",
    "\n",
    "science_and_technology--0.55      \n",
    "sports------------------0.66      \n",
    "video_games-------------0.85\n",
    "\n",
    "macro avg---------------0.69\n",
    "weighted avg------------0.79"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recall\n",
    "science_and_technology--0.44\n",
    "sports------------------0.61\n",
    "video_games-------------0.88\n",
    "macro avg---------------0.65\n",
    "weighted avg------------0.80\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F1-score\n",
    "science_and_technology--0.49\n",
    "sports------------------0.64\n",
    "video_games-------------0.87\n",
    "macro avg---------------0.66\n",
    "weighted avg------------0.80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrix\n",
    "sciences_and_technology [[ 223   42  239]\n",
    "sports_games             [  43 1781 1078]\n",
    "video_games              [ 142  873 7579]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Neural Network Classifier with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the multi-label classifier dataset from earlier exercises (categorized-comments.jsonl in the reddit folder), fit a neural network classifier using Keras. Use the code found in chapter 12 of the Applied Text Analysis with Python book as a guideline. Report the accuracy, precision, recall, F1-score, and confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries for keras tutorial\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from numpy import loadtxt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sports</td>\n",
       "      <td>Barely better than Gabbert? He was significant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sports</td>\n",
       "      <td>Fuck the ducks and the Angels! But welcome to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sports</td>\n",
       "      <td>Should have drafted more WRs.\\n\\n- Matt Millen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sports</td>\n",
       "      <td>[Done](https://i.imgur.com/2YZ90pm.jpg)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sports</td>\n",
       "      <td>No!! NOO!!!!!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cat                                                txt\n",
       "0  sports  Barely better than Gabbert? He was significant...\n",
       "1  sports  Fuck the ducks and the Angels! But welcome to ...\n",
       "2  sports  Should have drafted more WRs.\\n\\n- Matt Millen...\n",
       "3  sports            [Done](https://i.imgur.com/2YZ90pm.jpg)\n",
       "4  sports                                      No!! NOO!!!!!"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read the file\n",
    "jfile = \"categorized-comments.jsonl\" #File location\n",
    "file = pd.read_json(jfile,lines=True) #Read command\n",
    "file.head() #Check the datarame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(606476, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Size of the dataframe\n",
    "file.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "video_games               435542\n",
       "sports                    145823\n",
       "science_and_technology     25111\n",
       "Name: cat, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How are the categories split\n",
    "file.cat.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Break the single df into multiple df\n",
    "video = file[file['cat'] == 'video_games']\n",
    "sports = file[file['cat'] == 'sports']\n",
    "sci_tech = file[file['cat'] == 'science_and_technology']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video file:                 cat                                                txt\n",
      "65873   video_games                                           Nvm then\n",
      "65874   video_games                             Hit speed 0,5 seconds.\n",
      "65875   video_games  I don't have any. FFS THIS IS SO EASY TO SEE! ...\n",
      "65876   video_games                                         On wheels?\n",
      "65877   video_games         Nice!Good to see lumberjack in your deck \n",
      "...             ...                                                ...\n",
      "606471  video_games             No. It's probably only happened to you\n",
      "606472  video_games  I think most of the disappointment came from t...\n",
      "606473  video_games  dishonored 1/2 looked like arse, so what the h...\n",
      "606474  video_games                                          [removed]\n",
      "606475  video_games  I wish more games provided options like Rise o...\n",
      "\n",
      "[435542 rows x 2 columns]\n",
      "Sports file:            cat                                                txt\n",
      "0       sports  Barely better than Gabbert? He was significant...\n",
      "1       sports  Fuck the ducks and the Angels! But welcome to ...\n",
      "2       sports  Should have drafted more WRs.\\n\\n- Matt Millen...\n",
      "3       sports            [Done](https://i.imgur.com/2YZ90pm.jpg)\n",
      "4       sports                                      No!! NOO!!!!!\n",
      "...        ...                                                ...\n",
      "373069  sports  Yeah but who cares we get a nice first rounder...\n",
      "373070  sports  Us doing well in November and three-fourths of...\n",
      "373071  sports  Would the meteor also destroy the rest of the ...\n",
      "373072  sports  Problem is half of those games are gonna be ag...\n",
      "373073  sports      Willy not exactly humble lol\\n\\nLove it\\n\\n\\n\n",
      "\n",
      "[145823 rows x 2 columns]\n",
      "Sci and Tech file:                           cat  \\\n",
      "3556   science_and_technology   \n",
      "3557   science_and_technology   \n",
      "3558   science_and_technology   \n",
      "3559   science_and_technology   \n",
      "3560   science_and_technology   \n",
      "...                       ...   \n",
      "28662  science_and_technology   \n",
      "28663  science_and_technology   \n",
      "28664  science_and_technology   \n",
      "28665  science_and_technology   \n",
      "28666  science_and_technology   \n",
      "\n",
      "                                                     txt  \n",
      "3556   Really blue and I mean really blue. Not exactl...  \n",
      "3557   That is a hell of a deal, I wish I had a use f...  \n",
      "3558   Have 50/50 internet, and once had the most hor...  \n",
      "3559   Surely they could expand the screen size. As l...  \n",
      "3560                                       Sadly they do  \n",
      "...                                                  ...  \n",
      "28662                                          [deleted]  \n",
      "28663                                          [removed]  \n",
      "28664  That reminds me of the time my Galaxy S4's cap...  \n",
      "28665  I see what you mean.\\n\\nRumor has it that Goog...  \n",
      "28666                                             Wrong!  \n",
      "\n",
      "[25111 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#Quick preview\n",
    "print('Video file:',video)\n",
    "\n",
    "print('Sports file:', sports)\n",
    "\n",
    "print ('Sci and Tech file:', sci_tech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get samples 25000 sample from each\n",
    "video_small = video.sample(25000)\n",
    "sports_small = sports.sample(25000)\n",
    "sci_tech_small = sci_tech.sample(25000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75000, 2)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Put the files back into a single file with equal number of samples\n",
    "# Concatenate data frames by categories into one\n",
    "file_small_eql = pd.concat([video_small, sports_small, sci_tech_small])\n",
    "file_small_eql.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75000, 2)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check point copy\n",
    "file_small_eql_copy1=file_small_eql.copy(deep=True)\n",
    "#Check it again\n",
    "file_small_eql.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75000, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use only if needed to backup a step\n",
    "file_small_eql=file_small_eql_copy1.copy(deep=True)\n",
    "#Check restored file\n",
    "file_small_eql.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>336645</th>\n",
       "      <td>video_games</td>\n",
       "      <td>i know this is days old but thank you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119394</th>\n",
       "      <td>video_games</td>\n",
       "      <td>yes an objective based game mode that forces t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165323</th>\n",
       "      <td>video_games</td>\n",
       "      <td>httpsmsdnmicrosoftcomenuslibraryms176020aspxf2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311732</th>\n",
       "      <td>video_games</td>\n",
       "      <td>thats what im saying when i said such a large ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302492</th>\n",
       "      <td>video_games</td>\n",
       "      <td>i know its not quite on the same level but i n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                cat                                                txt\n",
       "336645  video_games              i know this is days old but thank you\n",
       "119394  video_games  yes an objective based game mode that forces t...\n",
       "165323  video_games  httpsmsdnmicrosoftcomenuslibraryms176020aspxf2...\n",
       "311732  video_games  thats what im saying when i said such a large ...\n",
       "302492  video_games  i know its not quite on the same level but i n..."
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lowercase the data\n",
    "file_small_eql[\"txt\"] = file_small_eql[\"txt\"].str.lower()\n",
    "#View the top 5 rows\n",
    "\n",
    "#Remove punctuation\n",
    "file_small_eql[\"txt\"] = file_small_eql[\"txt\"].str.replace(\"[^\\w\\s]\", \"\")\n",
    "#View the top 5 rows\n",
    "file_small_eql.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Tushar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Tushar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Download stopwords and punkt\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import NLKT, stopwords and tokenize\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "#Set the stop_words\n",
    "stop_words = stopwords.words(\"english\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75000, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_small_eql.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stop words\n",
    "file_small_eql[\"txt\"] = file_small_eql[\"txt\"].apply(lambda x: \" \".join([word for word in x.split()\n",
    "                                                                        if word not in (stop_words)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                            cat  \\\n",
       "389124             video_games   \n",
       "402969             video_games   \n",
       "568902             video_games   \n",
       "385986             video_games   \n",
       "335282             video_games   \n",
       "...                        ...   \n",
       "25824   science_and_technology   \n",
       "7676    science_and_technology   \n",
       "27345   science_and_technology   \n",
       "17095   science_and_technology   \n",
       "5518    science_and_technology   \n",
       "\n",
       "                                                      txt  \n",
       "389124                                         bloodborne  \n",
       "402969                                   one day nintendo  \n",
       "568902  yup struggle real blizzard puts lot faith play...  \n",
       "385986  diablo game switch would amazing even torchlig...  \n",
       "335282       sell goes back sold weeks ago 870k want back  \n",
       "...                                                   ...  \n",
       "25824   ill go ahead disagree priceperformance aspect ...  \n",
       "7676    different would android experience s7e vs used...  \n",
       "27345                    least get fast wireless charging  \n",
       "17095   low light decent close 6p area awesome autofoc...  \n",
       "5518                                        deez stickers  \n",
       "\n",
       "[75000 rows x 2 columns]>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_small_eql.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import PorterStemmer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "#Create stemmer\n",
    "porter = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>336645</th>\n",
       "      <td>video_games</td>\n",
       "      <td>know day old thank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119394</th>\n",
       "      <td>video_games</td>\n",
       "      <td>ye object base game mode forc team move spawn win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165323</th>\n",
       "      <td>video_games</td>\n",
       "      <td>httpsmsdnmicrosoftcomenuslibraryms176020aspxf2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311732</th>\n",
       "      <td>video_games</td>\n",
       "      <td>that im say said larg chunk busi wouldnt care ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302492</th>\n",
       "      <td>video_games</td>\n",
       "      <td>know quit level need sli cooper</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                cat                                                txt\n",
       "336645  video_games                                 know day old thank\n",
       "119394  video_games  ye object base game mode forc team move spawn win\n",
       "165323  video_games  httpsmsdnmicrosoftcomenuslibraryms176020aspxf2...\n",
       "311732  video_games  that im say said larg chunk busi wouldnt care ...\n",
       "302492  video_games                    know quit level need sli cooper"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run stemmer\n",
    "file_small_eql[\"txt\"]= file_small_eql[\"txt\"].apply(lambda x: \" \".join([porter.stem(word) for word in x.split()]))\n",
    "#View the file\n",
    "file_small_eql.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    25000\n",
       "1    25000\n",
       "0    25000\n",
       "Name: cat, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use encoder to convert categories to numerical values\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "cat = file_small_eql[\"cat\"]\n",
    "file_small_eql[\"cat\"]=encoder.fit_transform(cat)\n",
    "#Check the values\n",
    "file_small_eql.cat.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bring in CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75000, 44629)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create the bag of words features Features = X\n",
    "count=CountVectorizer()\n",
    "X=count.fit_transform(file_small_eql[\"txt\"])\n",
    "y = file_small_eql[\"cat\"]\n",
    "#Check it\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75000,)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Target Preview\n",
    "y=file_small_eql[\"cat\"]\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "336645    2\n",
       "119394    2\n",
       "165323    2\n",
       "311732    2\n",
       "302492    2\n",
       "         ..\n",
       "8816      0\n",
       "12951     0\n",
       "19722     0\n",
       "16215     0\n",
       "12531     0\n",
       "Name: cat, Length: 75000, dtype: int32"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Quick preview\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Split the data into train and text dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size = 0.20, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Training set: (60000, 44629)\n",
      "Y Training set: (60000,)\n",
      "X Test: (15000, 44629)\n",
      "Y Test: (15000,)\n"
     ]
    }
   ],
   "source": [
    "#Preview the train test dataset\n",
    "print('X Training set:',X_train.shape)\n",
    "\n",
    "print ('Y Training set:',y_train.shape)\n",
    "\n",
    "print ('X Test:',X_test.shape)\n",
    "\n",
    "print ('Y Test:',y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<60000x44629 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 762848 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to arrays for easy of use\n",
    "y_train = np.asarray(y_train)\n",
    "y_test = np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#PReview\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to convert to dense matrix\n",
    "def tensor(X):\n",
    "    coo = X.tocoo()\n",
    "    indices = np.mat([coo.row, coo.col]).transpose()\n",
    "    return tf.sparse.reorder(tf.SparseTensor(indices, coo.data, coo.shape))\n",
    "\n",
    "\n",
    "# Define function to convert sparse matrix to sparse tensor\n",
    "#def convert_sparse_matrix_to_sparse_tensor(X):\n",
    "#    coo = X.tocoo()\n",
    "#    indices = np.mat([coo.row, coo.col]).transpose()\n",
    "#    return tf.sparse.reorder(tf.SparseTensor(indices, coo.data, coo.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make them dense\n",
    "X_train = tensor(X_train)\n",
    "X_test = tensor(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.framework.sparse_tensor.SparseTensor at 0x20ec8775df0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check what comes out\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing Neural Network\n",
    "classifier = Sequential()\n",
    "\n",
    "#Set input feature\n",
    "N_FEATURES = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create keras sequential classifier \n",
    "\n",
    "#Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(500, activation='relu', input_dim=N_FEATURES))\n",
    "#Adding the second hidden layer\n",
    "classifier.add(Dense(700, activation='relu'))\n",
    "#Adding the output layer\n",
    "classifier.add(Dense(10, activation='softmax'))\n",
    "\n",
    "#Compile the Artificial Neural Network\n",
    "classifier.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "120/120 [==============================] - 13s 99ms/step - loss: 1.0372 - accuracy: 0.6224\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 15s 127ms/step - loss: 0.4031 - accuracy: 0.8257\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 16s 132ms/step - loss: 0.2985 - accuracy: 0.8656\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 16s 128ms/step - loss: 0.2343 - accuracy: 0.8938\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 15s 124ms/step - loss: 0.1793 - accuracy: 0.9176\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 16s 132ms/step - loss: 0.1455 - accuracy: 0.9323\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 17s 140ms/step - loss: 0.1270 - accuracy: 0.9376\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 16s 133ms/step - loss: 0.1149 - accuracy: 0.9449\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 16s 134ms/step - loss: 0.1081 - accuracy: 0.9471\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 17s 140ms/step - loss: 0.1012 - accuracy: 0.9494\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20ec8e26d90>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit training set\n",
    "classifier.fit(X_train, y_train, batch_size=500, epochs=10, verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create prediction\n",
    "y_pred = np.argmax(classifier.predict(X_test), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4021  440  558]\n",
      " [ 477 3706  733]\n",
      " [ 714  913 3438]]\n"
     ]
    }
   ],
   "source": [
    "#COnfusion Matrix\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.80      0.79      5019\n",
      "           1       0.73      0.75      0.74      4916\n",
      "           2       0.73      0.68      0.70      5065\n",
      "\n",
      "    accuracy                           0.74     15000\n",
      "   macro avg       0.74      0.74      0.74     15000\n",
      "weighted avg       0.74      0.74      0.74     15000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification Report\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7443333333333333\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuray 74.43%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Classifying Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In chapter 20 of the Machine Learning with Python Cookbook, implement the code found in section 20.15 classify MSINT images using a convolutional neural network. Report the accuracy of your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set that the color channel value will be first\n",
    "K.set_image_data_format(\"channels_first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed\n",
    "np.random.seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set image information\n",
    "channels = 1\n",
    "height = 28\n",
    "width = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and target from MNIST data\n",
    "(data_train, target_train), (data_test, target_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape training image data into features\n",
    "data_train = data_train.reshape(data_train.shape[0], channels, height, width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape test image data into features\n",
    "data_test = data_test.reshape(data_test.shape[0], channels, height, width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescale pixel intensity to between 0 and 1\n",
    "features_train = data_train / 255\n",
    "features_test = data_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode target\n",
    "target_train = np_utils.to_categorical(target_train)\n",
    "target_test = np_utils.to_categorical(target_test)\n",
    "number_of_classes = target_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start neural network\n",
    "network = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add convolutional layer with 64 filters, a 5x5 window, and ReLU activation function\n",
    "network.add(Conv2D(filters=64,\n",
    "                   kernel_size=(5, 5),\n",
    "                   input_shape=(channels, width, height),\n",
    "                   activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add max pooling layer with a 2x2 window\n",
    "network.add(MaxPooling2D(pool_size=(2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add dropout layer\n",
    "network.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add layer to flatten input\n",
    "network.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Add fully connected layer of 128 units with a ReLU activation function\n",
    "network.add(Dense(128, activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add dropout layer\n",
    "network.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add fully connected layer with a softmax activation function\n",
    "network.add(Dense(number_of_classes, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile neural network\n",
    "network.compile(loss=\"categorical_crossentropy\", # Cross-entropy\n",
    "                optimizer=\"rmsprop\", # Root Mean Square Propagation\n",
    "                metrics=[\"accuracy\"]) # Accuracy performance metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "60/60 - 40s - loss: 0.0822 - accuracy: 0.9758 - val_loss: 0.0441 - val_accuracy: 0.9860\n",
      "Epoch 2/2\n",
      "60/60 - 44s - loss: 0.0716 - accuracy: 0.9786 - val_loss: 0.0405 - val_accuracy: 0.9852\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22a7ebc0a90>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train neural network\n",
    "network.fit(features_train, # Features\n",
    "            target_train, # Target\n",
    "            epochs=2, # Number of epochs\n",
    "            verbose=2, # Don't print description after each epoch\n",
    "            batch_size=1000, # Number of observations per batch\n",
    "            validation_data=(features_test, target_test)) # Data for evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report the accuracy of your results.\n",
    "The accuracy 98.60 and 98.52 the two epochs ran."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
